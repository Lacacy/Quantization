{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15986978-6582-436b-a241-82437484b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "671cceca-02f7-418c-a262-59f95f98f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histgram_range(x):\n",
    "    hist, range = np.histogram(x, 100)\n",
    "    total = len(x)\n",
    "    left = 0\n",
    "    right = len(hist) - 1\n",
    "    limit = 0.99\n",
    "    while True:\n",
    "        cover_percent = hist[left:right].sum()/total\n",
    "        if cover_percent <= limit:\n",
    "            break\n",
    "            \n",
    "        if hist[left] > hist[right]:\n",
    "            right -= 1\n",
    "        else:\n",
    "            left += 1\n",
    "            \n",
    "    left_val = range[left]\n",
    "    right_val = range[right]\n",
    "    dynamic_range = max(abs(left_val), abs(right_val))\n",
    "    return dynamic_range/127."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cdf8199-f658-403f-858b-636698a87f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### KL 散度校准\n",
    "def KL(p, q):\n",
    "    pk = 1.0 * p / np.sum(p)\n",
    "    qk = 1.0 * q / np.sum(q)\n",
    "    t = 0\n",
    "    for i in range(pk.shape[0]):\n",
    "        t += pk[i] * np.log(pk[i]) - pk[i] * np.log(qk[i])\n",
    "        \n",
    "    return t\n",
    "    \n",
    "def entropy(x, target_bin = 128):\n",
    "    # 计算最大绝对值\n",
    "    amax = np.abs(x).max()\n",
    "    # 计算直方图分布\n",
    "    distribution, _ = np.histogram(x, bins=2048, range=(0, amax))\n",
    "    # 遍历直方图分布\n",
    "    distribution = distribution[1:]\n",
    "    length = distribution.size\n",
    "    # 定义 KL 散度\n",
    "    kl_divergence = np.zeros(length-target_bin)\n",
    "    # 遍历 [127:2047]\n",
    "    for threshold in range(target_bin, length):\n",
    "        sliced_nd_hist = copy.deepcopy(distribution[:threshold])\n",
    "        # 复制切分分布\n",
    "        p = sliced_nd_hist.copy()\n",
    "        threshold_sum = sum(distribution[:threshold])\n",
    "        \n",
    "        # 边界外的组加到边界p[i-1]上, 没有直接\n",
    "        p[threshold - 1] += threshold_sum\n",
    "        is_nonzeros = (p != 0).astype(np.int64)\n",
    "        \n",
    "        # 合并bins, 步长为: num_merged_bins = sliced_nd_hist.size // target_bin = 16\n",
    "        quantized_bins = np.zeros(target_bin, dtype=np.int64)\n",
    "        num_merged_bins = sliced_nd_hist.size // target_bin\n",
    "        \n",
    "        for j in range(target_bin):\n",
    "            start = j * num_merged_bins\n",
    "            stop = start + num_merged_bins\n",
    "            quantized_bins[j] = sliced_nd_hist[start:stop].sum()\n",
    "            quantized_bins[-1] += sliced_nd_hist[target_bin * num_merged_bins:].sum()\n",
    "            \n",
    "            # 定义分布： q, 这里的size 要和 p 分布一致, 也就是和sliced_hd_hist 分布一致\n",
    "            q = np.zeros(sliced_nd_hist.size, dtype=np.float64)\n",
    "                \n",
    "            # 根据步长结合 p 的 非零以及 quant_p 来以步长填充 q\n",
    "            for j in range(target_bin):\n",
    "                start = j * num_merged_bins\n",
    "                stop = -1 if j == target_bin - 1 else start + num_merged_bins\n",
    "                norm = is_nonzeros[start:stop].sum()\n",
    "                q[start:stop] = float(quantized_bins[j]) / float(norm) if norm != 0 else q[start:stop]\n",
    "                \n",
    "                p = p / sum(p)\n",
    "                q = q / sum(q)\n",
    "                \n",
    "                # 计算 KL 散度\n",
    "                kl_divergence[threshold - target_bin] = KL(p, q)\n",
    "                \n",
    "        min_kl_divergence = np.argmin(kl_divergence)\n",
    "        threshold_value = min_kl_divergence + target_bin\n",
    "        \n",
    "        scale = (threshold_value + 0.5) * (amax / 2048) / 127.0\n",
    "        \n",
    "        return scale\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93156d5d-1d03-4086-9c79-23a7b6b527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.seed(1)\n",
    "\n",
    "weights = np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9492c07f-f8f1-488a-8ec4-183c0378dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-362c82c568f6>:53: RuntimeWarning: invalid value encountered in true_divide\n",
      "  q = q / sum(q)\n",
      "<ipython-input-46-362c82c568f6>:7: RuntimeWarning: divide by zero encountered in log\n",
      "  t += pk[i] * np.log(pk[i]) - pk[i] * np.log(qk[i])\n",
      "<ipython-input-46-362c82c568f6>:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  t += pk[i] * np.log(pk[i]) - pk[i] * np.log(qk[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022388924156632888 0.0019557411396902615\n"
     ]
    }
   ],
   "source": [
    "scale_2 = histgram_range(weights)\n",
    "scale_3 = entropy(weights)\n",
    "print(scale_2, scale_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0d04b50-b0d8-4049-8469-18f2d0c18dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-85-75958b438dec>:48: RuntimeWarning: divide by zero encountered in log\n",
      "  t += pk[i] * np.log(pk[i]) - pk[i] * np.log(qk[i])\n",
      "<ipython-input-85-75958b438dec>:48: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  t += pk[i] * np.log(pk[i]) - pk[i] * np.log(qk[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy  mse error:  1.8921579013846344\n",
      "histogram  mse error:  21.659925933513303\n",
      "max  mse error:  23.191319960042705\n"
     ]
    }
   ],
   "source": [
    "### compare\n",
    "\n",
    "import numpy as np \n",
    "import copy\n",
    "\n",
    "\n",
    "# Max 校准 \n",
    "def maxq(value):\n",
    "    dynamic_range = np.abs(value).max()\n",
    "    scale = dynamic_range / 127.0\n",
    "    return scale\n",
    "\n",
    "# 直方图校准 \n",
    "def histogramq(value):\n",
    "    # 计算直方图\n",
    "    hist, bins = np.histogram(value, 100)\n",
    "    total = len(value)\n",
    "    left, right = 0, len(hist)\n",
    "    limit = 0.99\n",
    "    while True:\n",
    "        nleft = left + 1\n",
    "        nright = right + 1\n",
    "        left_cover = hist[nleft:right].sum() / total\n",
    "        right_cover = hist[left:nright].sum() / total\n",
    "        # 判断是否 left 和 right 都小于limit 的限度，True 退出\n",
    "        if left_cover < limit and right_cover < limit:\n",
    "            break\n",
    "        if left_cover > right_cover:\n",
    "            left += 1\n",
    "        else:\n",
    "            right -= 1\n",
    "                \n",
    "        # 根据直方图占比和limit 计算的left 和right 边界，确定value 中的数值边界\n",
    "        low, high = bins[left], bins[right - 1]\n",
    "        # 计算最大绝对值边界\n",
    "        dynamic_range = max(abs(low), abs(high))\n",
    "        # 计算scale\n",
    "        scale = dynamic_range / 127.0\n",
    "        return scale\n",
    "    \n",
    "    \n",
    "# KL 散度校准 \n",
    "def KL(p, q):\n",
    "    pk = 1.0 * p / np.sum(p)\n",
    "    qk = 1.0 * q / np.sum(q)\n",
    "    t = 0\n",
    "    for i in range(pk.shape[0]):\n",
    "        t += pk[i] * np.log(pk[i]) - pk[i] * np.log(qk[i])\n",
    "    return t\n",
    "\n",
    "def entropy(value, target_bin=128):\n",
    "    # 计算最大绝对值\n",
    "    amax = np.abs(value).max()\n",
    "    # 计算直方图分布\n",
    "    distribution, _ = np.histogram(value, bins=2048, range = (0, amax))\n",
    "    # 遍历直方图分布\n",
    "    distribution = distribution[1:]\n",
    "    length = distribution.size\n",
    "    # 定义KL散度\n",
    "    kl_divergence = np.zeros(length - target_bin)\n",
    "    # 遍历 [128:2047]\n",
    "    for threshold in range(target_bin, length):\n",
    "        sliced_nd_hist = copy.deepcopy(distribution[:threshold])\n",
    "        # 复制切分分布为：p\n",
    "        p = sliced_nd_hist.copy()\n",
    "        threshold_sum = sum(distribution[threshold:])\n",
    "        \n",
    "#         边界外的组加到边界p[i-1]上，没有直接\n",
    "        p[threshold - 1] += threshold_sum\n",
    "        is_nonzeros = (p != 0).astype(np.int64)\n",
    "        \n",
    "#   合并bins, 步长为： num_merged_bins = sliced_nd_hist.size // target_bin = 16\n",
    "        quantized_bins = np.zeros(target_bin, dtype=np.int64)\n",
    "        num_merged_bins = sliced_nd_hist.size // target_bin\n",
    "        \n",
    "        for j in range(target_bin): \n",
    "            start = j * num_merged_bins\n",
    "            stop = start + num_merged_bins\n",
    "            quantized_bins[j] = sliced_nd_hist[start:stop].sum()\n",
    "            quantized_bins[-1] += sliced_nd_hist[target_bin * num_merged_bins:].sum()\n",
    "            \n",
    "            # 定义分布: q , 这里的size 要和p分布一致， 也就是和sliced_hd_hist 分布一致\n",
    "            q = np.zeros(sliced_nd_hist.size, dtype=np.float64)\n",
    "            \n",
    "        # 根据步长结合p的非零以及 quant_p, 来以步长填充 q\n",
    "        for j in range(target_bin):\n",
    "            start = j * num_merged_bins\n",
    "            stop = -1 if j == target_bin - 1 else start + num_merged_bins\n",
    "            norm = is_nonzeros[start:stop].sum()\n",
    "            q[start:stop] = float(quantized_bins[j]) / float(norm) if norm != 0 else q[start:stop]\n",
    "            \n",
    "        p = p / sum(p)\n",
    "        q = q / sum(q)\n",
    "        \n",
    "        # 计算KL散度\n",
    "        kl_divergence[threshold - target_bin] = KL(p, q)\n",
    "        \n",
    "    min_kl_divergence = np.argmin(kl_divergence)\n",
    "    threshold_value = min_kl_divergence + target_bin\n",
    "    scale = (threshold_value + 0.5) * (amax / 2048) / 127.0\n",
    "        \n",
    "    return scale\n",
    "        \n",
    "# int8截断， 注意，-128去调不要 \n",
    "def saturate(x):\n",
    "    return np.clip(np.round(x), -127, +127)\n",
    "\n",
    "\n",
    "class Quant:\n",
    "    def __init__(self, value, s='max') -> None:\n",
    "        if s == 'max':\n",
    "            self.scale = maxq(value)\n",
    "        if s == 'histogram':\n",
    "            self.scale = histogramq(value)\n",
    "        if s == 'entropy':\n",
    "            self.scale = entropy(value)\n",
    "    \n",
    "    def __call__(self, f):\n",
    "        return saturate(f / self.scale)\n",
    "    \n",
    "        \n",
    "def Quant_Conv(x, w, b, iq, wq, oq=None):\n",
    "    alpha = iq.scale * wq.scale\n",
    "    out_int32 = iq(x) * wq(w)\n",
    "    if oq is None:  \n",
    "        return out_int32 * alpha + b\n",
    "    else:\n",
    "        return saturate((out_int32 * alpha + b) / oq.scale)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    nelem = 1000\n",
    "    for s in ['entropy', 'histogram', 'max']:\n",
    "    \n",
    "#     for s in ['histogram', 'max']:\n",
    "        np.random.seed(1)\n",
    "        # 生成随机权重、输入与偏置向量\n",
    "        x = np.random.randn(nelem)\n",
    "        weight1 = np.random.randn(nelem)\n",
    "        bias1 = np.random.randn(nelem)\n",
    "        \n",
    "        # 计算第一层卷积计算的结果输出（fp32)\n",
    "        t = x * weight1 + bias1\n",
    "        weight2 = np.random.randn(nelem)\n",
    "        bias2 = np.random.randn(nelem)\n",
    "        \n",
    "        \n",
    "        # 计算第二层卷积计算的结果输出（fp32)\n",
    "        y = t * weight2 + bias2\n",
    "        # 分别对输入、权重以及中间层输出（也是下一层的输入）进行量化校准\n",
    "        xQ = Quant(x, s)\n",
    "        w1Q = Quant(weight1, s)\n",
    "\n",
    "        tQ = Quant(t, s)\n",
    "        w2Q = Quant(weight2, s)\n",
    "        qt = Quant_Conv(x, weight1, bias1, xQ, w1Q, tQ)\n",
    "        # int8计算的结果输出\n",
    "        y2 = Quant_Conv(qt, weight2, bias2, tQ, w2Q)\n",
    "        # 计算量化计算的均方差\n",
    "        y_diff = (np.abs(y-y2) ** 2).mean()\n",
    "        print(s, \" mse error: \", y_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cc604-e893-4877-b603-dfb789b77ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffe7c3-ab91-46b0-83a4-a977dc70360f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
